<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>batch` on GGfu Personal Study - 學習筆記</title><link>https://ggfu0114.github.io/tags/batch/</link><description>Recent content in batch` on GGfu Personal Study - 學習筆記</description><generator>Hugo -- gohugo.io</generator><language>zh-tw</language><lastBuildDate>Sun, 06 Mar 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://ggfu0114.github.io/tags/batch/index.xml" rel="self" type="application/rss+xml"/><item><title>Deploy s3 bucket by cloudformation</title><link>https://ggfu0114.github.io/posts/deploy-s3-bucket-by-cloudformation/</link><pubDate>Sun, 06 Mar 2022 00:00:00 +0000</pubDate><guid>https://ggfu0114.github.io/posts/deploy-s3-bucket-by-cloudformation/</guid><description>預先準備 需要先把 aws cli 給裝起來
利用CLI可以把預先寫好的基礎建設結構佈署到AWS上，下面是簡單部署一個S3的bucket範例。
aws cloudformation deploy --stack-name paulteststack --template-file ./s3-create-template.json --stack-name: 想要deploy到哪一個cloudformation stack裡 --template-file: template 檔案的所在位置 還有很多參數可以設定，詳情可以參考 create-stack
{ &amp;#34;AWSTemplateFormatVersion&amp;#34;: &amp;#34;2010-09-09&amp;#34;, &amp;#34;Description&amp;#34;: &amp;#34;Create S3 bucket on AWS&amp;#34;, &amp;#34;Resources&amp;#34;: { &amp;#34;S3Test&amp;#34;: { &amp;#34;Type&amp;#34;: &amp;#34;AWS::S3::Bucket&amp;#34;, &amp;#34;Properties&amp;#34;: { &amp;#34;BucketName&amp;#34;: &amp;#34;paul-test-1495611707&amp;#34; } } } } template 可以依照情境進行更進階的調整，例如調整bucket的CROS讓外部的前端程式可以進行存取。 { &amp;#34;AWSTemplateFormatVersion&amp;#34;: &amp;#34;2010-09-09&amp;#34;, &amp;#34;Description&amp;#34;: &amp;#34;Create S3 bucket on AWS&amp;#34;, &amp;#34;Resources&amp;#34;: { &amp;#34;S3Test&amp;#34;: { &amp;#34;Type&amp;#34;: &amp;#34;AWS::S3::Bucket&amp;#34;, &amp;#34;Properties&amp;#34;: { &amp;#34;BucketName&amp;#34;: &amp;#34;paul-test-1495611707&amp;#34;, &amp;#34;AccessControl&amp;#34;: &amp;#34;PublicReadWrite&amp;#34;, &amp;#34;CorsConfiguration&amp;#34;: { &amp;#34;CorsRules&amp;#34;: [ { &amp;#34;AllowedHeaders&amp;#34;: [ &amp;#34;*&amp;#34; ], &amp;#34;AllowedMethods&amp;#34;: [ &amp;#34;GET&amp;#34; ], &amp;#34;AllowedOrigins&amp;#34;: [ &amp;#34;*&amp;#34; ], &amp;#34;ExposedHeaders&amp;#34;: [ &amp;#34;Date&amp;#34; ], &amp;#34;Id&amp;#34;: &amp;#34;myCORSRuleId1&amp;#34;, &amp;#34;MaxAge&amp;#34;: &amp;#34;3600&amp;#34; }, { &amp;#34;AllowedHeaders&amp;#34;: [ &amp;#34;x-amz-*&amp;#34; ], &amp;#34;AllowedMethods&amp;#34;: [ &amp;#34;DELETE&amp;#34; ], &amp;#34;AllowedOrigins&amp;#34;: [ &amp;#34;http://www.</description></item><item><title>收集 AWS IoT data到 AWS kinesis 處理資料流</title><link>https://ggfu0114.github.io/posts/%E6%94%B6%E9%9B%86-aws-iot-data%E5%88%B0-aws-kinesis-%E8%99%95%E7%90%86%E8%B3%87%E6%96%99%E6%B5%81/</link><pubDate>Sun, 06 Mar 2022 00:00:00 +0000</pubDate><guid>https://ggfu0114.github.io/posts/%E6%94%B6%E9%9B%86-aws-iot-data%E5%88%B0-aws-kinesis-%E8%99%95%E7%90%86%E8%B3%87%E6%96%99%E6%B5%81/</guid><description> 使用AWS IoT服務來開發大量的資料傳輸系統，主要是想彙整資料或是做數據分析，AWS同樣提供資料串流的分析服務 kinesis. kinesis服務裡面有三個類別，Data Streams, Data Firehose, Data Analytics. Data Streams: streams 這個服務其實就有點類似 Kafka. 在IoT mqtt的protocol下，publish/subscribe之間系統是不會保存任何傳遞的資料。所以一但需要做資料流分析時，需要將收到的資料存在Message Queue裡，kinesis streams就擔任這個初階的角色，stream可以搭配firhorsec，analytics，lambda&amp;hellip;一起使用。
Data Firehose: firehose可以將stream的資料倒至其他AWS的服務，例如： S3, Redshift&amp;hellip;，firehose服務裡提供transformation功能將資料整理成需要的格式。
Data Analytics: 利用收到的data stream，只要提供需要sql程式，設定好Source(data stream)與Destination，AWS就會提供即時分析服務。
IoT trigger Kinese stream
只要在IoT的Service上建立rule，只要推送資料到設定的topi就會將資料導入Kinese stream。 選定 Send messages to an Kinesis Stream 就可以在符合Rule時將資料導入data stream 選定預先創立好的stream，設定Partition key，還有執行角色就完成 Partition key說明
利用Partition key，IoT的資料可以藉由group的方式去將資料分配的儲存在stream的shards裡面，最容易的方式是用網頁上提供的function: newuuid()，去隨機產出亂數平均的儲存資料，或是利用IoT的資料裡面的Key直做group。 [{&amp;#39;key&amp;#39;:&amp;#39;a1&amp;#39;, &amp;#39;value&amp;#39;:1}, {&amp;#39;key&amp;#39;:&amp;#39;a2&amp;#39;, &amp;#39;value&amp;#39;:2}, {&amp;#39;key&amp;#39;:&amp;#39;a1&amp;#39;, &amp;#39;value&amp;#39;:3}] 如果Partition key填入${key}，那麼第1,3比資料會被送到stream裡的同一個shard，2則被送到另一個shard。
trigger lambda處理收集好的batch資料
shard只由一個lambda服務 pull 多shard由多個lambda執行task, semphore問題</description></item></channel></rss>