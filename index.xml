<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>GGfu Personal Study - 學習筆記</title><link>https://ggfu0114.github.io/</link><description>Recent content on GGfu Personal Study - 學習筆記</description><generator>Hugo -- gohugo.io</generator><language>zh-tw</language><lastBuildDate>Sun, 26 Jun 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://ggfu0114.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>Google cloud storage產生signed url的應用</title><link>https://ggfu0114.github.io/posts/gcp_signed_url/</link><pubDate>Sun, 26 Jun 2022 00:00:00 +0000</pubDate><guid>https://ggfu0114.github.io/posts/gcp_signed_url/</guid><description>Signed url的目的跟說明 這個功能主要是讓系統認可的使用者可以透過取的一個暫時的網址去存取雲端空間的權限
目前市面上有很多雲端提供者(cloud provider)，例如Google(GCP), Amazon, Azure&amp;hellip;，他們都提供網路空間上開發者進行系統整合。
但是這些的空間通常因爲安全性(Security)的考量，都會將空間設定是私人，為的是防止有心人隨意上傳檔案。 但是會衍生出系統使用者(user)並沒有辦法上傳檔案，為了解決這個問題上 signed URL這個機制。
使用者必須先透過系統驗證機制(帳號/密碼, oauth&amp;hellip;)讓系統知道使用者是誰之後，系統認可後為使用者製造出一段暫時性的網址，讓使用者去上傳或者是瀏覽檔案系統
在此篇文章中我們針對Google service的進行說明
如何做到Signed url的機制 使用者必須透過驗證機制讓伺服器知道他是合法的使用者，如此一來伺服器可以為使用者製造出一個暫時有權限的網址，並透過API回傳給使用者，使用者取的後就可以使用這個網址直接上傳到目標的空間。當有心人士想上傳不合法的檔案，會因為無取得系統的認可而不能上傳檔案(因為folder預設會是privated)。
Debug過程 Send PUT http request to upload the file to a GCS bucket. And then the error message pop up on the chrome dev console. :::danger Access to XMLHttpRequest at &amp;lsquo;https://storage.googleapis.com/xxxxxx' from origin &amp;lsquo;http://127.0.0.1:5000&amp;rsquo; has been blocked by CORS policy: No &amp;lsquo;Access-Control-Allow-Origin&amp;rsquo; header is present on the requested resource. ::: You have to update the bucket CORS policy by running following command.</description></item><item><title>Deploy s3 bucket by cloudformation</title><link>https://ggfu0114.github.io/posts/deploy-s3-bucket-by-cloudformation/</link><pubDate>Sun, 06 Mar 2022 00:00:00 +0000</pubDate><guid>https://ggfu0114.github.io/posts/deploy-s3-bucket-by-cloudformation/</guid><description>預先準備 需要先把 aws cli 給裝起來
利用CLI可以把預先寫好的基礎建設結構佈署到AWS上，下面是簡單部署一個S3的bucket範例。
aws cloudformation deploy --stack-name paulteststack --template-file ./s3-create-template.json --stack-name: 想要deploy到哪一個cloudformation stack裡 --template-file: template 檔案的所在位置 還有很多參數可以設定，詳情可以參考 create-stack
{ &amp;#34;AWSTemplateFormatVersion&amp;#34;: &amp;#34;2010-09-09&amp;#34;, &amp;#34;Description&amp;#34;: &amp;#34;Create S3 bucket on AWS&amp;#34;, &amp;#34;Resources&amp;#34;: { &amp;#34;S3Test&amp;#34;: { &amp;#34;Type&amp;#34;: &amp;#34;AWS::S3::Bucket&amp;#34;, &amp;#34;Properties&amp;#34;: { &amp;#34;BucketName&amp;#34;: &amp;#34;paul-test-1495611707&amp;#34; } } } } template 可以依照情境進行更進階的調整，例如調整bucket的CROS讓外部的前端程式可以進行存取。 { &amp;#34;AWSTemplateFormatVersion&amp;#34;: &amp;#34;2010-09-09&amp;#34;, &amp;#34;Description&amp;#34;: &amp;#34;Create S3 bucket on AWS&amp;#34;, &amp;#34;Resources&amp;#34;: { &amp;#34;S3Test&amp;#34;: { &amp;#34;Type&amp;#34;: &amp;#34;AWS::S3::Bucket&amp;#34;, &amp;#34;Properties&amp;#34;: { &amp;#34;BucketName&amp;#34;: &amp;#34;paul-test-1495611707&amp;#34;, &amp;#34;AccessControl&amp;#34;: &amp;#34;PublicReadWrite&amp;#34;, &amp;#34;CorsConfiguration&amp;#34;: { &amp;#34;CorsRules&amp;#34;: [ { &amp;#34;AllowedHeaders&amp;#34;: [ &amp;#34;*&amp;#34; ], &amp;#34;AllowedMethods&amp;#34;: [ &amp;#34;GET&amp;#34; ], &amp;#34;AllowedOrigins&amp;#34;: [ &amp;#34;*&amp;#34; ], &amp;#34;ExposedHeaders&amp;#34;: [ &amp;#34;Date&amp;#34; ], &amp;#34;Id&amp;#34;: &amp;#34;myCORSRuleId1&amp;#34;, &amp;#34;MaxAge&amp;#34;: &amp;#34;3600&amp;#34; }, { &amp;#34;AllowedHeaders&amp;#34;: [ &amp;#34;x-amz-*&amp;#34; ], &amp;#34;AllowedMethods&amp;#34;: [ &amp;#34;DELETE&amp;#34; ], &amp;#34;AllowedOrigins&amp;#34;: [ &amp;#34;http://www.</description></item><item><title>Deploy s3 bucket by cloudformation - 進階版</title><link>https://ggfu0114.github.io/posts/deploy-s3-bucket-by-cloudformation-%E9%80%B2%E9%9A%8E%E7%89%88/</link><pubDate>Sun, 06 Mar 2022 00:00:00 +0000</pubDate><guid>https://ggfu0114.github.io/posts/deploy-s3-bucket-by-cloudformation-%E9%80%B2%E9%9A%8E%E7%89%88/</guid><description>開發系統時部分的程式碼會參考到基礎建設的名稱，例如：S3 bucket自動部署創建出來的名稱，或是需要利用aws resource arn去做trigger lambda事件的綁定，都需要輸出佈建後的結果。 { &amp;#34;AWSTemplateFormatVersion&amp;#34;: &amp;#34;2010-09-09&amp;#34;, &amp;#34;Description&amp;#34;: &amp;#34;Create S3 bucket on AWS&amp;#34;, &amp;#34;Parameters&amp;#34;: { &amp;#34;StageName&amp;#34;: { &amp;#34;Type&amp;#34;: &amp;#34;String&amp;#34; } }, &amp;#34;Resources&amp;#34;: { &amp;#34;S3Test&amp;#34;: { &amp;#34;Type&amp;#34;: &amp;#34;AWS::S3::Bucket&amp;#34;, &amp;#34;Properties&amp;#34;: { &amp;#34;BucketName&amp;#34;: { &amp;#34;Fn::Sub&amp;#34;: [ &amp;#34;paul-test-${StageName}&amp;#34;, { &amp;#34;StageName&amp;#34;: { &amp;#34;Ref&amp;#34;: &amp;#34;StageName&amp;#34; } } ] }, &amp;#34;AccessControl&amp;#34;: &amp;#34;PublicReadWrite&amp;#34;, &amp;#34;CorsConfiguration&amp;#34;: { &amp;#34;CorsRules&amp;#34;: [ { &amp;#34;AllowedHeaders&amp;#34;: [ &amp;#34;*&amp;#34; ], &amp;#34;AllowedMethods&amp;#34;: [ &amp;#34;GET&amp;#34; ], &amp;#34;AllowedOrigins&amp;#34;: [ &amp;#34;*&amp;#34; ], &amp;#34;ExposedHeaders&amp;#34;: [ &amp;#34;Date&amp;#34; ], &amp;#34;Id&amp;#34;: &amp;#34;myCORSRuleId1&amp;#34;, &amp;#34;MaxAge&amp;#34;: &amp;#34;3600&amp;#34; } ] } } } }, &amp;#34;Outputs&amp;#34;: { &amp;#34;S3Test&amp;#34;: { &amp;#34;Description&amp;#34;: &amp;#34;Information about s3 bucket name&amp;#34;, &amp;#34;Value&amp;#34;: { &amp;#34;Fn::Sub&amp;#34;: [ &amp;#34;paul-test-${StageName}&amp;#34;, { &amp;#34;StageName&amp;#34;: { &amp;#34;Ref&amp;#34;: &amp;#34;StageName&amp;#34; } } ] }, &amp;#34;Export&amp;#34;: { &amp;#34;Name&amp;#34;: { &amp;#34;Fn::Sub&amp;#34;: [ &amp;#34;${StackName}-S3Test-bucketname&amp;#34;, { &amp;#34;StackName&amp;#34;: { &amp;#34;Ref&amp;#34;: &amp;#34;AWS::StackName&amp;#34; } } ] } } } } } Fn::Sub: 代表字串裡的變數，可用接下來的變數給取代。當字串不需要有變數取代時，可以簡單的利用{ &amp;quot;Fn::Sub&amp;quot; : String }描述即可。需要由變數替換的模板為{ &amp;quot;Fn::Sub&amp;quot; : [ String, { Var1Name: Var1Value, Var2Name: Var2Value } ] }。</description></item><item><title>Druid</title><link>https://ggfu0114.github.io/posts/druid/</link><pubDate>Sun, 06 Mar 2022 00:00:00 +0000</pubDate><guid>https://ggfu0114.github.io/posts/druid/</guid><description>Druid Terms multi-tenant: a single instance of software runs on a server and serves multiple tenants OLAP: Online analytical processing, is an approach to answering multi-dimensional analytical (MDA) queries swiftly in computing SaaS: a software distribution model in which a third-party provider hosts applications and makes them available to customers over the Internet ROLL-UP: 將原始數據在匯入資料庫時就進行彙整處理
Scenario 資料已經整理好，不需要更新操作 不需要做表格的join 對於資料時間維度要求比較高的工作 即時性極重要的project External Dependencies Zookeeper: cluster內部溝通資訊所用 Metadata Storage: 儲存segment的meta data和configuration，提供coordinator node去調配segment的的載入情況 Deep Storage: segment的永久儲存空間，提供Historical node去下載segment</description></item><item><title>Kubernate Env Setup FAQ(by Kubeadm)</title><link>https://ggfu0114.github.io/posts/kubernate-env-setup-faqby-kubeadm/</link><pubDate>Sun, 06 Mar 2022 00:00:00 +0000</pubDate><guid>https://ggfu0114.github.io/posts/kubernate-env-setup-faqby-kubeadm/</guid><description>前置作業 如何關掉swap功能： 如果是linux，可透過以下指令去關掉swap功能 sudo swapoff -a &amp;amp;&amp;amp; sudo sed -i '/swap/d' /etc/fstab
安裝執行工具 安裝kubelet kubeadm kubectl的方法
sudo apt-get update &amp;amp;&amp;amp; sudo apt-get install -y apt-transport-https curl sudo curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add - sudo cat &amp;lt;&amp;lt;EOF &amp;gt;/etc/apt/sources.list.d/kubernetes.list deb http://apt.kubernetes.io/ kubernetes-xenial main EOF sudo apt-get update sudo apt-get install -y kubelet kubeadm kubectl sudo apt-mark hold kubelet kubeadm kubectl 官網說明：https://kubernetes.io/docs/setup/independent/install-kubeadm/
開始架設 將電腦變成master node可執行：
kubeadm init 首先adm會先去做幾項檢測 通過後會下載跟安裝k8s所需要的控制元件
安裝過程的錯誤 Q1 Unable to connect to the server: x509: certificate signed by unknown authority (possibly because of &amp;#34;crypto/rsa: verification error&amp;#34; while trying to verify candidate authority certificate &amp;#34;kubernetes&amp;#34;) 主要是因為沒執行以下的動作，導致user的權限不符合，無法使用kubctl cmd</description></item><item><title>PgPool2 install issu 紀錄安裝過程</title><link>https://ggfu0114.github.io/posts/pgpool2-install-issu-%E7%B4%80%E9%8C%84%E5%AE%89%E8%A3%9D%E9%81%8E%E7%A8%8B/</link><pubDate>Sun, 06 Mar 2022 00:00:00 +0000</pubDate><guid>https://ggfu0114.github.io/posts/pgpool2-install-issu-%E7%B4%80%E9%8C%84%E5%AE%89%E8%A3%9D%E9%81%8E%E7%A8%8B/</guid><description>安裝pgpool-II 透過網路上簡易的git repostory去快速的安裝pgpool-2 docker環境 例如：docker-pgpool2
將pgpool conf檔跟執行的shell複製進去docker裡面 執行pgpool 需要在postgres建立pgpool所需要登入的角色，例如使用者：pgpool
利用指令可以查詢現在postgres node status:
pcp_node_info [option...] [node_id] pcp_node_info --verbose -h localhost -U postgres 0 問題 出現2018-09-18 05:32:46: pid 6: FATAL: could not open pid file as /var/run/pgpool/pgpool.pid. reason: No such file or directory的錯誤訊息 需要幫process建立/var/run/pgpool的資料夾
pgpool都已經裝好，postgres sever也已經就緒，但是出現無法登入的問題，相同帳號密碼不透過pgpool會登入成功？
看了一下pgpool2的log檔，出現以下資訊
2018-07-27 06:51:28 DEBUG: pid 30: I am 30 accept fd 5 2018-07-27 06:51:28 LOG: pid 30: connection received: host=192.168.17.178 port=64325 2018-07-27 06:51:28 DEBUG: pid 30: Protocol Major: 1234 Minor: 5679 database: user: 2018-07-27 06:51:28 DEBUG: pid 30: SSLRequest from client 2018-07-27 06:51:28 DEBUG: pid 30: read_startup_packet: application_name: pgAdmin 4 - DB:postgres 2018-07-27 06:51:28 DEBUG: pid 30: Protocol Major: 3 Minor: 0 database: postgres user: postgres 2018-07-27 06:51:28 DEBUG: pid 30: new_connection: connecting 0 backend 2018-07-27 06:51:28 DEBUG: pid 30: new_connection: skipping slot 0 because backend_status = 0 2018-07-27 06:51:28 DEBUG: pid 30: new_connection: connecting 1 backend 2018-07-27 06:51:28 DEBUG: pid 30: pool_read_message_length: slot: 1 length: 12 2018-07-27 06:51:28 DEBUG: pid 30: pool_do_auth: auth kind:5 2018-07-27 06:51:28 DEBUG: pid 30: trying md5 authentication 2018-07-27 06:51:28 ERROR: pid 30: pool_get_passwd: username is NULL 2018-07-27 06:51:28 DEBUG: pid 30: do_md5: (null) does not exist in pool_passwd 2018-07-27 06:51:28 DEBUG: pid 30: do_md5failed in slot 1 正常普通安裝pgpool，設定檔的路徑會出現在/etc/pgpool2，通常會有四個檔案，pcp.</description></item><item><title>S3 multipart uplaod prsigned url教學</title><link>https://ggfu0114.github.io/posts/s3-multipart-uplaod-prsigned-url%E6%95%99%E5%AD%B8/</link><pubDate>Sun, 06 Mar 2022 00:00:00 +0000</pubDate><guid>https://ggfu0114.github.io/posts/s3-multipart-uplaod-prsigned-url%E6%95%99%E5%AD%B8/</guid><description>當系統需要做續傳功能或大檔上傳的功能時，S3提供multipart upload的功能，可將檔案切分上傳，最後到S3再進行合併。主要分成3步驟：
Multipart upload init 上傳一個或多個parts Multipart upload complete 上傳初始化 檔案要上傳到S3時，需指明當這個 multipart upload 完成組合成一個 object 後，object 的 key 值為何，若希望以 multipart upload 建立的 object 帶有自訂的 metadata，亦須在 multipart upload 初始化時提供。成功初始化後，S3會建立一組 upload ID 當成未來上傳為此 object 的依據。
&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;UTF-8&amp;#34;?&amp;gt; &amp;lt;InitiateMultipartUploadResult xmlns=&amp;#34;http://s3.amazonaws.com/doc/2006-03-01/&amp;#34;&amp;gt; &amp;lt;Bucket&amp;gt;test201705021548&amp;lt;/Bucket&amp;gt; &amp;lt;Key&amp;gt;hello.jpg&amp;lt;/Key&amp;gt; &amp;lt;UploadId&amp;gt;QAUmLo15J46MyspVk6PgCPg7C1yk9RdOR2XfsdwEe2xDVS33HTh.cAJzFfwcug--&amp;lt;/UploadId&amp;gt; &amp;lt;/InitiateMultipartUploadResult&amp;gt; 操作步驟
為 init multipart 的需求產出數位簽章。 var StringToSign = &amp;#34;POST&amp;#34; + &amp;#34;\n&amp;#34; + &amp;#34;&amp;#34; + &amp;#34;\n&amp;#34; + &amp;#34;&amp;#34; + &amp;#34;\n&amp;#34; + new Date().toUTCString() + &amp;#34;\n&amp;#34; + &amp;#34;/test201705021548/hello.jpg?uploads&amp;#34;; init成功時，S3會回傳對應的 upload ID</description></item><item><title>收集 AWS IoT data到 AWS kinesis 處理資料流</title><link>https://ggfu0114.github.io/posts/%E6%94%B6%E9%9B%86-aws-iot-data%E5%88%B0-aws-kinesis-%E8%99%95%E7%90%86%E8%B3%87%E6%96%99%E6%B5%81/</link><pubDate>Sun, 06 Mar 2022 00:00:00 +0000</pubDate><guid>https://ggfu0114.github.io/posts/%E6%94%B6%E9%9B%86-aws-iot-data%E5%88%B0-aws-kinesis-%E8%99%95%E7%90%86%E8%B3%87%E6%96%99%E6%B5%81/</guid><description> 使用AWS IoT服務來開發大量的資料傳輸系統，主要是想彙整資料或是做數據分析，AWS同樣提供資料串流的分析服務 kinesis. kinesis服務裡面有三個類別，Data Streams, Data Firehose, Data Analytics. Data Streams: streams 這個服務其實就有點類似 Kafka. 在IoT mqtt的protocol下，publish/subscribe之間系統是不會保存任何傳遞的資料。所以一但需要做資料流分析時，需要將收到的資料存在Message Queue裡，kinesis streams就擔任這個初階的角色，stream可以搭配firhorsec，analytics，lambda&amp;hellip;一起使用。
Data Firehose: firehose可以將stream的資料倒至其他AWS的服務，例如： S3, Redshift&amp;hellip;，firehose服務裡提供transformation功能將資料整理成需要的格式。
Data Analytics: 利用收到的data stream，只要提供需要sql程式，設定好Source(data stream)與Destination，AWS就會提供即時分析服務。
IoT trigger Kinese stream
只要在IoT的Service上建立rule，只要推送資料到設定的topi就會將資料導入Kinese stream。 選定 Send messages to an Kinesis Stream 就可以在符合Rule時將資料導入data stream 選定預先創立好的stream，設定Partition key，還有執行角色就完成 Partition key說明
利用Partition key，IoT的資料可以藉由group的方式去將資料分配的儲存在stream的shards裡面，最容易的方式是用網頁上提供的function: newuuid()，去隨機產出亂數平均的儲存資料，或是利用IoT的資料裡面的Key直做group。 [{&amp;#39;key&amp;#39;:&amp;#39;a1&amp;#39;, &amp;#39;value&amp;#39;:1}, {&amp;#39;key&amp;#39;:&amp;#39;a2&amp;#39;, &amp;#39;value&amp;#39;:2}, {&amp;#39;key&amp;#39;:&amp;#39;a1&amp;#39;, &amp;#39;value&amp;#39;:3}] 如果Partition key填入${key}，那麼第1,3比資料會被送到stream裡的同一個shard，2則被送到另一個shard。
trigger lambda處理收集好的batch資料
shard只由一個lambda服務 pull 多shard由多個lambda執行task, semphore問題</description></item><item><title>Flask 第一個 APP(初學入門)</title><link>https://ggfu0114.github.io/posts/flask-%E7%AC%AC%E4%B8%80%E5%80%8B-app%E5%88%9D%E5%AD%B8%E5%85%A5%E9%96%80/</link><pubDate>Thu, 01 Jul 2021 00:00:00 +0000</pubDate><guid>https://ggfu0114.github.io/posts/flask-%E7%AC%AC%E4%B8%80%E5%80%8B-app%E5%88%9D%E5%AD%B8%E5%85%A5%E9%96%80/</guid><description>學了Python卻不知道可以應用在哪裡? 這個影片包含了
如何寫一個最簡單的Web server 做好的網站要怎麼執行 我想要Debug該怎麼做 點選以下影片觀看↘↘
設定或開發環境遇到問題了?
請看影片：Python的開發環境設定
檔案介紹 main.py: 整個Flask APP 主要的進入檔案
requirement.txt: 執行APP所需要的相依套件(開發工程師不可能所有功能都自己獨立製作，所以需要很多Open Source的套件來輔助，完成一套用的系統)
程式碼解說 @app.route(&amp;#39;/&amp;#39;) URL的入口點，當使用者打錯網址時， APP沒有辦法找到對應的function來處理時，就會出現 404 not found 的錯誤。
return &amp;#34;&amp;lt;div&amp;gt;Hello World, gFu.&amp;lt;div&amp;gt;&amp;#34; 當使用者連上正確的URL時，APP就會幫忙處理資料，但是這個簡單的範例並沒多加複雜的邏輯，只有回傳單純的html元素給使用者。</description></item><item><title>Flask 要如何做測試</title><link>https://ggfu0114.github.io/posts/flask-%E8%A6%81%E5%A6%82%E4%BD%95%E5%81%9A%E6%B8%AC%E8%A9%A6/</link><pubDate>Thu, 01 Jul 2021 00:00:00 +0000</pubDate><guid>https://ggfu0114.github.io/posts/flask-%E8%A6%81%E5%A6%82%E4%BD%95%E5%81%9A%E6%B8%AC%E8%A9%A6/</guid><description>flask-unittest 為什麼需要寫測試 寫測試對許多初學者來說，會覺的非常費時且沒有必要，心裡想著，我都親自測試過了，程式執行起來沒有什麼問題，為什麼需要花很多時間測試呢？
對於這個疑問，最簡單的回答是，寫測試大多是為了未來
專案只有幾個情況下比較不需要寫測試：
專案只會執行幾次就不再使用 還在初期的規規劃跟實驗的狀態(POC) 當你的專案有以下的情況,測試程式碼就會勢在必行：
越寫多程式碼,程式的複雜度跟耦合度漸漸變高時 專案成員變多,程式碼改動變頻繁的時候 測試程式碼就變的極為重要 測試可以讓你所開發的程式碼不會受到別人的改動而遭受影響(Side effect),當然要配合Dev Ops的CI/CD 效果才會比較好. Pytest vs. unittest
在Python內建的模組裡有包含了測試，所以不需要安裝任何第3方套件就可以載入unittest模組來寫測試. 我個人式比較常用pytest.
pytest的好處是：
提供比unittest更多的輔助工具來幫助測試 所有用unitest語法寫的測試程式碼,都可以用pytest來執行 執行測試 在Terminal上面執行pytest指令並加上一個資料夾，pytest就會自動去收集這個資料夾裡面帶有test_*.py 或是 *_test.py檔名的測試並執行
pytest tests -v -s -v: 描述詳細的測試訊息 -s: 顯示程式碼裡面印出來的資訊
Unittest Mock Mock 的功能對於測試非常的重要，例如：A function 裡面包含執行 B, C, D功能，但是在測試 A 功能時，我們並不想要測試 C 功能，只需要 bypass C 功能，這個時候 Mock 功能就派上用場.
patch 是Mock裡面所提供的一個功能，它可以去取代掉原本功能的過程，例如：
@patch(&amp;#39;func.MathFunc.get_random_point&amp;#39;) def test_multiply(self, mock_func): mock_func.return_value = (8, 6) 以上的程式碼代表，原本的get_random_point功能想要被取代，不論原本那個功能裡面的邏輯是什麼, 最終回傳值就一定會是一個tuple包含8,6這兩個值。
Flask test 利用Flask在寫Web Application時, 通常會進行API test.</description></item><item><title>Python的開發環境設定</title><link>https://ggfu0114.github.io/posts/python%E7%9A%84%E9%96%8B%E7%99%BC%E7%92%B0%E5%A2%83%E8%A8%AD%E5%AE%9A/</link><pubDate>Thu, 01 Jul 2021 00:00:00 +0000</pubDate><guid>https://ggfu0114.github.io/posts/python%E7%9A%84%E9%96%8B%E7%99%BC%E7%92%B0%E5%A2%83%E8%A8%AD%E5%AE%9A/</guid><description>針對Python初學者，這個影片解釋了以下幾問題：
如何下載程式碼 Virtual Environment 程式的執行&amp;amp;相依套件的安裝 點選以下影片觀看↘↘</description></item><item><title>AWS api-getway 客製化的 Domain Name</title><link>https://ggfu0114.github.io/posts/aws_api_getway_domain_name/</link><pubDate>Thu, 31 Dec 2020 00:00:00 +0000</pubDate><guid>https://ggfu0114.github.io/posts/aws_api_getway_domain_name/</guid><description>AWS api-getway Customized Domain Name 利用AWS的serverless服務開發 httpserver的情況下，很常會使用(Lambda+Apigateway)的服務，通常會用api-getway去當url route的服務。部屬成功時，api-getway都會給一組類似以下的網址，https://${api-id}.execute-api.region.amazonaws.com/stage ，因為網址有可能因為部署的需求而改變，所以如果想要制定自己的url名稱，就得使用api-getway裡面的custom domain name功能。
設定custom domain name分成以下幾個主要步驟
申請AWS ACM(AWS Certificate Manager)服務 綁定ACM服務到api-gateway 將route53綁定到api-gateway產出的CDN網址 申請AWS ACM
如果要使用custom domain name，我們得提供有效的SSL/TLS certificate保護我們的網址。ACM是AWS專門管理或產出SSL/TLS憑證的服務，需要在上面申請保護我們的url，請注意!!! 如果是因custom domain name而需申請ACM的話，請將申請區域調到 ==US East (N. Virginia)== 。ACM
申請的畫面會如下圖，如果想保護所有subdoamin可以用wildcard寫法，使用號，例如：.example.com 申請結束後AWS會寄信給domain擁有人(基本上就是開發者)，要求是否同意授權保護此網址，只要點擊連結就會啟用服務。 api-gateway綁定ACM
申請好ACM就可以將custom domain name綁定到api-getway上。填好要綁定的domain名稱，剛創建好的ACM服務，與選定mapping的api-getway即可。綁定的過程中會出現 Target Domain Name 這個就要最後一步要將route53指向的cloud front網址。 route53 綁定 cdn
登入進 route 53，為自己的domain建立一個A record，將target指向剛剛所產生的cloud front網址。 以上步驟都完成時就可以使用自己所設定的domain name去存取server了。</description></item><item><title>AWS IoT | 進階資訊分享</title><link>https://ggfu0114.github.io/posts/aws_iot_advance/</link><pubDate>Thu, 31 Dec 2020 00:00:00 +0000</pubDate><guid>https://ggfu0114.github.io/posts/aws_iot_advance/</guid><description>AWS IoT - 進階 IoT reserved topic 在 AWS IoT的資源上，有部份的 topic name是被保留。 $aws/events/presence/connected/# : 如果有任何的使用者連上 IoT 就會推播訊息到這個 Topic $aws/events/presence/disconnected/#: 如果有任何的使用者斷線,就會推播訊息
這個是當使用者 connected/disconnected 推播到 topic 裡的訊息範例 { &amp;#34;clientId&amp;#34;: &amp;#34;a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d6&amp;#34;, &amp;#34;timestamp&amp;#34;: 1460065214626, &amp;#34;eventType&amp;#34;: &amp;#34;connected&amp;#34;, &amp;#34;sessionIdentifier&amp;#34;: &amp;#34;00000000-0000-0000-0000-000000000000&amp;#34;, &amp;#34;principalIdentifier&amp;#34;: &amp;#34;000000000000/ABCDEFGHIJKLMNOPQRSTU:some-user/ABCDEFGHIJKLMNOPQRSTU:some-user&amp;#34; } $aws/events/subscriptions/subscribed/#: 如果有任何的使用者訂閱了任何的 topic就會推播訊息到這個topic $aws/events/subscriptions/unsubscribed/#： 如果有任何的使用者解訂閱了任何的 topic就會推播訊息
這個是 subscribed/unsubscribed 推播的訊息範例 { &amp;#34;clientId&amp;#34;: &amp;#34;186b5&amp;#34;, &amp;#34;timestamp&amp;#34;: 1460065214626, &amp;#34;eventType&amp;#34;: &amp;#34;subscribed&amp;#34; | &amp;#34;unsubscribed&amp;#34;, &amp;#34;sessionIdentifier&amp;#34;: &amp;#34;00000000-0000-0000-0000-000000000000&amp;#34;, &amp;#34;principalIdentifier&amp;#34;: &amp;#34;000000000000/ABCDEFGHIJKLMNOPQRSTU:some-user/ABCDEFGHIJKLMNOPQRSTU:some-user&amp;#34; &amp;#34;topics&amp;#34; : [&amp;#34;foo/bar&amp;#34;,&amp;#34;device/data&amp;#34;,&amp;#34;dog/cat&amp;#34;] } :::info
同時要聆聽相同 Topic 底下不同的子 Topic 可用 + 號串聯，例如： $aws/events/subscriptions/+/#: 可以同時聆聽到 connected, disconnected, subscribed, unsubscribed &amp;hellip;的訊息 company/+/member： + 號可以是任意的字串，只要符合這個 Topic 的 name 的規則，都可以收到資訊 :::</description></item><item><title>AWS IoT with websocket</title><link>https://ggfu0114.github.io/posts/aws_iot_websocket/</link><pubDate>Thu, 31 Dec 2020 00:00:00 +0000</pubDate><guid>https://ggfu0114.github.io/posts/aws_iot_websocket/</guid><description>在大多數的瀏覽器都有支援websocket的protocol前提下，實作網頁即時接收訊息的功能上，我們希望每個網頁都可以當作是一個mqtt的裝置，如此一來就可以即時推播給各個網頁，也可以即時的接收到來自client端的訊息。 AWS在IoT的服務上也有做到MQTT Over the WebSocket Protocol，透過AWS SigV4的身份認證, 利用Port 443，我們可以透過網頁連線上AWS IoT的服務。 server side
以下是server端需要產出帶有authentication的query url，使用上，前端只需要將url用get的方式呼叫就可以連接上IoT。 function SigV4Utils() {} SigV4Utils.getSignatureKey = function (key, date, region, service) { var kDate = AWS.util.crypto.hmac(&amp;#39;AWS4&amp;#39; + key, date, &amp;#39;buffer&amp;#39;); var kRegion = AWS.util.crypto.hmac(kDate, region, &amp;#39;buffer&amp;#39;); var kService = AWS.util.crypto.hmac(kRegion, service, &amp;#39;buffer&amp;#39;); var kCredentials = AWS.util.crypto.hmac(kService, &amp;#39;aws4_request&amp;#39;, &amp;#39;buffer&amp;#39;); return kCredentials; }; SigV4Utils.getSignedUrl = function(host, region, ) { var datetime = AWS.util.date.iso8601(new Date()).replace(/[:\-]|\.\d{3}/g, &amp;#39;&amp;#39;); var date = datetime.</description></item><item><title>AWS IoT介紹</title><link>https://ggfu0114.github.io/posts/aws_iot/</link><pubDate>Thu, 31 Dec 2020 00:00:00 +0000</pubDate><guid>https://ggfu0114.github.io/posts/aws_iot/</guid><description>AWS IoT 說明
certificate：裝置可以透過 certificates 去做驗證，保證使用 IoT 的溝通上 security 是沒有任何問題的。除了certificates之外，也可以透過IAM權限，Congnito 的權限控管去操作 IoT 的 resources (如上圖)。 利用 AWS IoT 提供的 sdk 可以在 AWS resource 內產出一組 certificate， 裏面包含的資訊會有certificate pem keyPair(a pair of public &amp;amp; private key) certificateId &amp;amp; ARN
取得憑證後，需要在憑證上套用policy，policy就好像規定這拿著這隻憑證鑰匙可以進哪個門，不能進哪個門，以達到 AWS IoT 的 resource 控管。
Policy設定 以下的這個 Policy設定代表使用者只要有合理的 certificates，就可以針對IoT上所有的resources 做連線，推播，接收的動做，沒做任何的限制管控，如果要限制使用者能力有下面另外一個範例 { &amp;#34;Version&amp;#34;: &amp;#34;2012-10-17&amp;#34;, &amp;#34;Statement&amp;#34;: [{ &amp;#34;Effect&amp;#34;: &amp;#34;Allow&amp;#34;, &amp;#34;Action&amp;#34;: [ &amp;#34;iot:Publish&amp;#34;, &amp;#34;iot:Subscribe&amp;#34;, &amp;#34;iot:Connect&amp;#34;, &amp;#34;iot:Receive&amp;#34; ], &amp;#34;Resource&amp;#34;: [&amp;#34;*&amp;#34;] }] } 如果想讓使用者只能針對自己 CertificateId 的 topic 操作，policy 就要修改成以下的方式，利用 ${iot:CertificateId} 的變數，AWS IoT 會去檢查裝置端連線時所使用的憑證，達到每個憑證只能操作對應憑證 ID 的 Topic，降低資訊被竊取的風險。 { &amp;#34;Version&amp;#34;: &amp;#34;2012-10-17&amp;#34;, &amp;#34;Statement&amp;#34;: [ { &amp;#34;Effect&amp;#34;: &amp;#34;Allow&amp;#34;, &amp;#34;Action&amp;#34;: &amp;#34;iot:Subscribe&amp;#34;, &amp;#34;Resource&amp;#34;: &amp;#34;arn:aws:iot:ap-northeast-1:1234:topicfilter/${iot:CertificateId}&amp;#34; }, { &amp;#34;Effect&amp;#34;: &amp;#34;Allow&amp;#34;, &amp;#34;Action&amp;#34;: &amp;#34;iot:Connect&amp;#34;, &amp;#34;Resource&amp;#34;: &amp;#34;arn:aws:iot:ap-northeast-1:1234:client/${iot:CertificateId}&amp;#34; }, { &amp;#34;Effect&amp;#34;: &amp;#34;Allow&amp;#34;, &amp;#34;Action&amp;#34;: [ &amp;#34;iot:Publish&amp;#34;, &amp;#34;iot:Receive&amp;#34; ], &amp;#34;Resource&amp;#34;: &amp;#34;arn:aws:iot:ap-northeast-1:1234:topic/${iot:CertificateId}&amp;#34; } ] } connect 的 policy 要跟操作 IoT resources 要分開寫，因為 connect 是針對 client resource 操作，但是其他的動作是針對 IoT 上的 topic resource 做操作，如果都在一條 statement 會導致錯誤。</description></item><item><title>AWS S3 REST 數位簽章與驗證</title><link>https://ggfu0114.github.io/posts/aws_s3_signed_url/</link><pubDate>Thu, 31 Dec 2020 00:00:00 +0000</pubDate><guid>https://ggfu0114.github.io/posts/aws_s3_signed_url/</guid><description>AWS S3 REST簽章與驗證 假設在S3裡的物件只設定給 &amp;ldquo;authenticated AWS user&amp;rdquo; 操作，那我們要如何利用數位簽章讓使用者可以透過 api resquest 去做身份認可(identity)並操作S3裏面的物件。 假設在S3上我們有一個name為 wisigntest 的bucket，裏面存在一個名為hello.jpg的物件，設定為 &amp;ldquo;authenticated AWS user&amp;rdquo; 可以R/W。我們將紀錄如何使用API去存取S3物件。 簡易瀏覽物件
GET /hello.jpg HTTP/1.1 Host: https://wisigntest.s3-ap-northeast-1.amazonaws.com Date: Fri, 28 Apr 2017 05:56:29 GMT Authorization: AWS AKIAIOSFODNN7EXAMPLE:frJIUN8DYpKDtOLCwo//yllqDzg= 下面是我用Postman去讀取S3檔案的畫面 The Authentication Header
下面的格式是主要傳送給 API 的 Header 上要添加的 Authorization 資訊，透過Signature，AWS可以驗證此次的操作是否有效。
Authorization: AWS {AWSAccessKeyId}:{Signature} 下面是 Nodejs 計算的Signature程式碼
var crypto = require(&amp;#34;crypto&amp;#34;); // from IAM role var secret_access_key = &amp;#39;64nd6BY7gTPDspq54gQcRth5dvORNdDvqL4BZ5zd&amp;#39;; var access_key_id = &amp;#39;AKIAIUHT2BNZP65ADZKQ&amp;#39; var StringToSign = &amp;#34;GET&amp;#34; + &amp;#34;\n&amp;#34; + &amp;#34;&amp;#34; + &amp;#34;\n&amp;#34; + &amp;#34;&amp;#34; + &amp;#34;\n&amp;#34; + new Date().</description></item><item><title>Ceph Cluster Storage 初階學習</title><link>https://ggfu0114.github.io/posts/ceph_beginner/</link><pubDate>Thu, 31 Dec 2020 00:00:00 +0000</pubDate><guid>https://ggfu0114.github.io/posts/ceph_beginner/</guid><description>Ceph 元件 MON (monitor): 維護整個cluster的狀態 透過crush演算法取得osd位置，執行建立與傳輸資料 不會主動的輪詢OSD的各種狀態 保證cluster所有數據的一致性 單一可運行，建議可部署多個，每個node上最多只能有一個MON OSD (ObjectStorageDevice) cluster中的資料的儲存體 - 當OSD發現自身或其他OSD發生異常時會上報MON - 對其他的OSD發送heart beat訊號 MGR MDS 使用CephFS才需要使用此服務 - 提供資料運算，緩存和資料同步 Ceph RGW(即RADOS Gateway)是Ceph对象存储网关服务，是基于LIBRADOS接口封装实现的FastCGI服务，对外提供存储和管理对象数据的Restful API。 安裝osd時有錯誤發生，發現log的描述如下： ** ERROR: osd init failed: (36) File name too long 原因： Ceph官方建議用XFS作OSD的文件系統，如果安裝OSD主機上的文件系統格式為ext4，會使得OSD的資料不能安全的保存。所以要解決這個問題就得：
將安裝OSD的文件系統改為XFS 修改OSD的文件配置，然後重新啟動OSD osd max object name len = 256 osd max object namespace len = 64 用來檢查Ceph目前的狀態
ceph -s 當Ceph系統都已經架設完畢時，可以安裝ceph-fuse作為Client端掛載到monitor機器上 sudo apt-get install ceph-fuse
$ ceph- fuse -m 192.168.0.1:6789 /fuse_folder/ 系統都已設定完畢，但是使用ceph-fuse出現</description></item><item><title>Javascript detect network connect status</title><link>https://ggfu0114.github.io/posts/js_network_alive/</link><pubDate>Thu, 31 Dec 2020 00:00:00 +0000</pubDate><guid>https://ggfu0114.github.io/posts/js_network_alive/</guid><description>[JS] detect network connect status 當我們在開發網站時，可能會遇到需要偵測網路情況，給予使用者是當的反饋。例如做檔案上傳時，如果網路斷線又回復連接時，需要提醒使用者可以做續傳的動作。目前市面上多樣的瀏覽器所提供的online/offline事件，可能沒有辦法有效的偵測到。 :::warning It is important to note that this event and attribute are inherently unreliable. A computer can be connected to a network without having Internet access. :::
目前各家瀏覽器針對 &amp;ldquo;Offline&amp;rdquo; 的定義都不相同，所以沒有一個有效率的方式可偵測瀏覽器的網路情況。斷線的定義位於broswer當電腦在受保護的私人網路下，所以沒有連線到外界網路的能力，要定義為Offline嗎？ 都沒接上網路但是client和server端都在127.0.0.1網段，可以互相溝通要算有網路嗎？ 一般開發網站時可能比較需要偵測連線到外埠網路的情況，所以下面是一斷偵測網路連線狀態的 example code。藉由嘗試存取自己網站的favicon.ico去判定對是否有網路的連線能力，我們透過 httprequest 的 HEADER method 去嘗試，再這個 method 下比較節省流量。HTTP Method :::warning The HEAD method asks for a response identical to that of a GET request, but without the response body :::
export function doesConnectionExist() { return new Promise((resolve) =&amp;gt; { const xhr = new XMLHttpRequest(); const url = &amp;#39;https://example.</description></item><item><title>Kubeflow Mnist範例介紹</title><link>https://ggfu0114.github.io/posts/kf_minst/</link><pubDate>Thu, 31 Dec 2020 00:00:00 +0000</pubDate><guid>https://ggfu0114.github.io/posts/kf_minst/</guid><description>官網的Git：kubeflow mnist
利用簡單的mnist來做為範例，介紹如何在Kubeflow進行training跟serving的流程。Kubeflow利用argo workflow將整個流程寫成腳本，透過指令驅動整個AI training與serving過程。training階段會將訓練model的程式碼包成docker image，建立TFjob將model訓練出來。serving階段，會將訓練好的model利用seldon-core的幫助，建立起prediction服務。 Training 的流程 將training的程式從git上載下來，打包成training image 將打包好的image推上去docker registry 利用TFjob執行image產生model 將model給volume出來 Serving 的流程 將serving的程式從git上載下來，打包成serving image 將打包好的image推上去docker registry 將剛train好的model給volume到seldon-core的image上 透過定義seldon graph啟動predict的機制 測試 可以利用seldon-core出的測試工具來檢視predict serving是否正確執行：
$ seldon-core-api-tester --ambassador-path /seldon/kubeflow/mnist-classifier -p contract.json &amp;lt;host ip&amp;gt; &amp;lt;host port&amp;gt; Debug 錯誤訊息：
error when creating &amp;#34;/tmp/manifest.yaml&amp;#34;: tfjobs.kubeflow.org is forbidden: User &amp;#34;system:serviceaccount:kubeflow:default&amp;#34; cannot create tfjobs.kubeflow.org in the namespace &amp;#34;kubeflow&amp;#34; 將kubeflow namespace的帳號default 加上cluster-admin的權限 kubectl create clusterrolebinding sa-admin --clusterrole=cluster-admin --serviceaccount=kubeflow:default 錯誤訊息：
Failed to submit workflow: workflows.argoproj.io is forbidden: User &amp;#34;system:serviceaccount:kubeflow:jupyter-notebook&amp;#34; cannot create workflows.</description></item><item><title>Kubeflow安裝及入門</title><link>https://ggfu0114.github.io/posts/kf_install/</link><pubDate>Thu, 31 Dec 2020 00:00:00 +0000</pubDate><guid>https://ggfu0114.github.io/posts/kf_install/</guid><description>安裝需求 安裝好ksonnet, Version 0.11.0 or later. Kubernetes 1.8 or later 安裝ksonnet export KS_VER=0.12.0 export KS_PKG=ks_${KS_VER}_linux_amd64 wget -O /tmp/${KS_PKG}.tar.gz https://github.com/ksonnet/ksonnet/releases/download/v${KS_VER}/${KS_PKG}.tar.gz \ --no-check-certificate mkdir -p ${HOME}/bin tar -xvf /tmp/$KS_PKG.tar.gz -C ${HOME}/bin export PATH=$PATH:${HOME}/bin/$KS_PKG 官方皆學的網站可以參考： linux install ks
安裝kubeflow 下載安裝kubeflow的script export KUBEFLOW_SRC=kf_src mkdir ${KUBEFLOW_SRC} cd ${KUBEFLOW_SRC} export KUBEFLOW_TAG=v0.3.1 curl https://raw.githubusercontent.com/kubeflow/kubeflow/${KUBEFLOW_TAG}/scripts/download.sh | bash 將下載好的ks檔部署到K8S環境上 export KFAPP=kf_conf scripts/kfctl.sh init ${KFAPP} --platform none cd ${KFAPP} ../scripts/kfctl.sh generate k8s ../scripts/kfctl.sh apply k8s 驗證kubeflow status 執行kubectl get pods --all-namespaces可以檢視目前pod運行的狀態 會發現有一個pod會是pending的狀態，vizier-db-547967c899-ppr4p 執行kubectl describe vizier-db-547967c899-ppr4p -n kubeflow 可以看到events出現以下字眼</description></item><item><title>Serverless offline 開發設定 - 基礎篇</title><link>https://ggfu0114.github.io/posts/aws_lambda_dev_offline/</link><pubDate>Thu, 31 Dec 2020 00:00:00 +0000</pubDate><guid>https://ggfu0114.github.io/posts/aws_lambda_dev_offline/</guid><description>說明
為了加速開發的效率，開發過程中不會想要每次都佈署到AWS做測試或開發。Serverless offline套件可以解決這件事情。透過模擬 AWS λ and API Gateway ，開發者在本機端就可以run一個的server去模擬再AWS服務的情況。
前置作業
需要事先安裝過 serverless package sudo npm install serverless -g 安裝serverless offline套件 npm install serverless-offline --save-dev
使用方法
在原本專案的serverless.yml上添加程式碼
plugins plugins: - serverless-offline server conf 將server在 3000 PORT 開啟; 開放所有的 IP 都可以存取
custom: serverless-offline: host: &amp;#34;0.0.0.0&amp;#34; port: 3000 在Terminal上啟動 serverless offline server serverless offline start 接著就可以用各種工具去發出request做開發測試
:::danger
執行API request出現錯誤 { &amp;#34;statusCode&amp;#34;: 400, &amp;#34;error&amp;#34;: &amp;#34;Bad Request&amp;#34;, &amp;#34;message&amp;#34;: &amp;#34;Invalid cookie value&amp;#34; } 經過測試，如果將IP綁在127.0.0.1或是沒有設定(系統預設為localhost)的話會出現access error，這個問題只要將 IP 綁在 0.</description></item><item><title>在Local machine開發AWS serverless project</title><link>https://ggfu0114.github.io/posts/aws_project_development/</link><pubDate>Thu, 31 Dec 2020 00:00:00 +0000</pubDate><guid>https://ggfu0114.github.io/posts/aws_project_development/</guid><description>AWS dev project 說明：這個 Project 主要是拿來研究 AWS serverless 的開發規劃和未來建構 Project 的基礎參考。主要會用到 AWS Resource 有 API-gateway, Lambda, RDS, Congnito Services。 Install 安裝 serverless package npm install -g serverless 安裝開發所需其他的套件 npm install Dev run Project 開發時，可在本機上做 Debug，確定Lambda的function沒有邏輯錯誤再佈署上去AWS就可以。Dev server開啟時會建立在 port 3000 上，請用自己主機 ip 連，不要用 127.0.0.1 或 localhost 連線，否則會出現錯誤。 npm run dev Deploy to AWS 將自己的程式碼透過serverless package上傳到 CloudFormation後佈署所需資源。 npm run deploy 為 API-gateway建立一個 Usage Plan aws apigateway create-usage-plan --name dev-file-sharing-plan --api-stages apiId={{API_ID}},stage=dev --region ap-northeast-1 為 Usage Plan 綁定一組 API-key aws apigateway create-usage-plan-key --usage-plan-id {{PLAN_ID}} --key-id {{KEY_ID}} --key-type &amp;quot;API_KEY&amp;quot; Migrations 建立一個 Migration 檔案 (若變更 Schema 則需要新增一個 Migration 檔案) db-migrate create &amp;lt;migrate_file&amp;gt; --config .</description></item><item><title>部屬Web application到K8S環境</title><link>https://ggfu0114.github.io/posts/app_on_k8s-copy/</link><pubDate>Thu, 31 Dec 2020 00:00:00 +0000</pubDate><guid>https://ggfu0114.github.io/posts/app_on_k8s-copy/</guid><description>Deploy first API server on K8S prepare server image docker pu image to registery
deploy pod on K8S 執行create pod指令時出現以下錯誤，代表目前K8S架構裡只有Master沒有Node
0/1 nodes are available: 1 node(s) had taints that the pod didn&amp;#39;t tolerate 執行 kubectl get pods -o wide 可以檢查目前pod的運行狀態
NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE my-pod 1/1 Running 0 19m 10.244.1.2 ubuntu &amp;lt;none&amp;gt; 驗證server是否已經成功的運行，可以用建立另一個暫時的pod，利用curl指令去取得server的資訊 kubectl run -i --tty alpine --image=alpine --restart=Never -- sh apk add curl curl -v http://10.</description></item><item><title>Dev issue: Lambda reuse</title><link>https://ggfu0114.github.io/posts/dev-issue_-lambda-reuse/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ggfu0114.github.io/posts/dev-issue_-lambda-reuse/</guid><description>當系統透過 APIGateway 呼叫 Lambda 執行時，我以為Lambda會全部重新執行打包好的程式。所以開發時，我們將 database connection 物件當成 Global 物件使用，認為每次重新呼叫 Lambda 都會全部重新生成物件。因為這個觀念而導致系統錯誤，當 Project 的物件被 require 後或變成 global 參數，再次執行 Lambda container 會出現 reuse 特性，將不會再被重新執行而生成新物件，以下是一個範例。 DB 的 client 為 global 物件
const pg = require(&amp;#39;pg&amp;#39;); const client = new pg.Client(&amp;#39;postgres://myrds:5432/dbname&amp;#39;); client.connect(); exports.handler = (event, context, cb) =&amp;gt; { const {test_print} = require(&amp;#39;./example_module&amp;#39;); test_print(); client.query(&amp;#39;SELECT * FROM users WHERE &amp;#39;, (err, users) =&amp;gt; { // Do stuff with users cb(null); // Finish the function cleanly }); }; 上面的範例，因為 client 為 global物件，所以如果在程式裡面有 disconnect client 的狀況下，再次執行 Lambda 就會出現錯誤，因為 client 物件沒被重新 connect。 Global 程式不會每次都被執行</description></item><item><title>部屬Web application到K8S環境</title><link>https://ggfu0114.github.io/posts/app_on_k8s/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ggfu0114.github.io/posts/app_on_k8s/</guid><description>Deploy first API server on K8S prepare server image docker pu image to registery
deploy pod on K8S 執行create pod指令時出現以下錯誤，代表目前K8S架構裡只有Master沒有Node
0/1 nodes are available: 1 node(s) had taints that the pod didn&amp;#39;t tolerate 執行 kubectl get pods -o wide 可以檢查目前pod的運行狀態
NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE my-pod 1/1 Running 0 19m 10.244.1.2 ubuntu &amp;lt;none&amp;gt; 驗證server是否已經成功的運行，可以用建立另一個暫時的pod，利用curl指令去取得server的資訊 kubectl run -i --tty alpine --image=alpine --restart=Never -- sh apk add curl curl -v http://10.</description></item></channel></rss>